{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Workflow for on-line GC and HPLC analysis in flow chemistry</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 0: Imports, Paths, and Logging\n",
    "---\n",
    "\n",
    "In this section all the necessary python packages are imported, the path to this notebook and the logger for this notebook is set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate autoreload to keep on track with changing modules #\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import standard libraries #\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "# Import tools for data processing and analysis and DaRUS upload #\n",
    "from FAIRFlowChemistry.tools import initialize_dataset, reading_raw_data_widget, analyzing_raw_data_widget, DaRUS_upload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for loggin output #\n",
    "root                = Path.cwd()\n",
    "logging_config_path = root / \"FAIRFlowChemistry/tools/logger_config.json\"\n",
    "\n",
    "# Read in logger specs and configurate logger (set name to current notebook) #\n",
    "with open(logging_config_path) as logging_config_json: logging.config.dictConfig( json.load( logging_config_json ) )\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the level of thid-party logger to avoid dumping too much information #\n",
    "for logger_ in ['markdown_it', 'h5py', 'numexpr', 'git']: logging.getLogger(logger_).setLevel('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Dataset and raw data\n",
    "---\n",
    "In this section the dataset as well as the to analyze raw data is choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4b8753da3f24c61b1bc37daaffb1290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Choose datamodel', layout=Layout(width='auto'), options=((…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset!\n"
     ]
    }
   ],
   "source": [
    "git_path = 'https://github.com/FAIRChemistry/FAIR_GC_analytics.git'\n",
    "branch   = 'samir_develop'\n",
    "\n",
    "id = initialize_dataset()\n",
    "id.write_dataset(root, git_path, branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definition of basic meta data of the project ##\n",
    "\n",
    "id.title.value        = 'Electrocatalytic CO2-reduction on carbon'\n",
    "id.description.value  = 'The aim of this project is to blablabla'\n",
    "id.project.value      = 'Project B07'\n",
    "\n",
    "# List with authors and their affiliation #\n",
    "id.authors.value      = 'Richard Schömig, Maximilian Schmidt' \n",
    "id.affiliations.value = 'University of Stuttgart, University of Stuttgart'\n",
    "id.identifier.value   = 'xxx-xxx-xxx-xxx, xxx-xxx-xxx-xxx'\n",
    "id.contact_text.value = 'Richard Schömig, richard@web.de'\n",
    "\n",
    "id.related_publication.value = \"test, https://id.loc.gov/authorities/subjects/sh2014001146.html\"\n",
    "\n",
    "id.topic_classification.value = \"homogeneous catalysis (LCSH), https://id.loc.gov/authorities/subjects/sh2014001146.html\"\n",
    "id.keywords.value             = \"polymer chemistry (Loterre Chemistry Vocabulary), https://skosmos.loterre.fr/ERC/en/page/?uri=http%3A%2F%2Fdata.loterre.fr%2Fark%3A%2F67375%2FERC-KCSKD4X9-P\"\n",
    "\n",
    "id.dataset_text.value = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3251c35df33a4549be13315e294adbbf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Choose dataset', layout=Layout(width='auto'), options=(('t…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Search for dataset and raw data ##\n",
    "\n",
    "rrdw = reading_raw_data_widget()\n",
    "rrdw.choose_data(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str(root) = \"c:/Users/darouich/OneDrive/Dokumente/\"\n",
    "\n",
    "e_chem = str(root)+'/data/Rohdaten/01_EChem/CAD14-Cu@AB/GSTATIC.DTA'\n",
    "mfm    = str(root)+'/data/Rohdaten/03_MFM/CAD14-Cu@AB/Bench-2h-GSS_CAD14-Cu@AB_200_50c_24h_truncated.csv'\n",
    "gc     = [str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0102.D/report00.CSV',\n",
    "        str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0102.D/REPORT01.CSV',\n",
    "        str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0103.D/report00.CSV',\n",
    "        str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0103.D/REPORT01.CSV',\n",
    "        str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0104.D/report00.CSV',\n",
    "        str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0104.D/REPORT01.CSV']\n",
    "calib  = str(root)+'/data/calibration/calibration.json'\n",
    "correc = str(root)+'/data/correction_factors/correction_factors.json'\n",
    "farada = str(root)+'/data/faraday_coefficients/faraday_coefficients.json'\n",
    "\n",
    "rrdw.Echem_files.value = [e_chem]\n",
    "rrdw.MFM_files.value   = [mfm]\n",
    "rrdw.GC_files.value    = gc\n",
    "rrdw.calib_files.value = [calib]\n",
    "rrdw.correction_files.value = [correc]\n",
    "rrdw.faraday_files.value    = [farada]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Analysis of data\n",
    "---\n",
    "In this section the raw data of the above choosen dataset is analyzed (if you change the dataset above, then reexecute this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9155f49a79e2491385e3642245a3a249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Choose experiment:', layout=Layout(width='auto'), options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0db800650e1345ddaa056d47fb99f137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Label(value='Measurement number 0', layout=Layout(height='30px', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031f1607c2ff41319056f02b56055b57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(HTML(value='The mass flow at the time of the GC measurement is determined by mat…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Provide a typical retention time dictionary to pre assign retention times \n",
    "\n",
    "typical_retention_time = {\"Hydrogen\": 1.7, \"Carbon dioxide\": 3.0, \"Carbon monoxide\": 13.6, \n",
    "                          \"Methane\": 3.6, \"Ethene\": 6.0, \"Ethane\": 7.1}\n",
    "\n",
    "ardw = analyzing_raw_data_widget()\n",
    "ardw.choose_experiment( dataset = rrdw.dataset, \n",
    "                        dataset_path = rrdw.dataset_dropdown.value, \n",
    "                        typical_retention_time = typical_retention_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Upload of data to DaRUS\n",
    "---\n",
    "In this section the above choosen dataset, containing the processed as well as the raw data, is uploaded to DaRUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da1d5814ff3e44e4a7bb4edaabf91ab0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Dropdown(description='Choose whether you want to create a new data record or edit an existing o…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "add_topic_classification() got an unexpected keyword argument 'term'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\darouich\\miniconda3\\Lib\\site-packages\\forge\\_revision.py:107\u001b[0m, in \u001b[0;36mMapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    106\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 107\u001b[0m     public_ba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpublic_signature\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbind\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\darouich\\miniconda3\\Lib\\inspect.py:3212\u001b[0m, in \u001b[0;36mSignature.bind\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   3208\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get a BoundArguments object, that maps the passed `args`\u001b[39;00m\n\u001b[0;32m   3209\u001b[0m \u001b[38;5;124;03mand `kwargs` to the function's signature.  Raises `TypeError`\u001b[39;00m\n\u001b[0;32m   3210\u001b[0m \u001b[38;5;124;03mif the passed arguments can not be bound.\u001b[39;00m\n\u001b[0;32m   3211\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3212\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bind\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\darouich\\miniconda3\\Lib\\inspect.py:3201\u001b[0m, in \u001b[0;36mSignature._bind\u001b[1;34m(self, args, kwargs, partial)\u001b[0m\n\u001b[0;32m   3200\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 3201\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m   3202\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgot an unexpected keyword argument \u001b[39m\u001b[38;5;132;01m{arg!r}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[0;32m   3203\u001b[0m                 arg\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(kwargs))))\n\u001b[0;32m   3205\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_arguments_cls(\u001b[38;5;28mself\u001b[39m, arguments)\n",
      "\u001b[1;31mTypeError\u001b[0m: got an unexpected keyword argument 'term'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\darouich\\OneDrive\\Dokumente\\datamodel_b07_tc\\datamodel_b07_tc\\FAIRFlowChemistry\\tools\\data_processing_widgets.py:772\u001b[0m, in \u001b[0;36mDaRUS_upload.upload_to_DaRUS\u001b[1;34m(self, _)\u001b[0m\n\u001b[0;32m    769\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDaRUS_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataverse\u001b[38;5;241m.\u001b[39mcreate_dataset()\n\u001b[0;32m    771\u001b[0m \u001b[38;5;66;03m# Fill in citation metadata from general information object\u001b[39;00m\n\u001b[1;32m--> 772\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfill_citation\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    774\u001b[0m \u001b[38;5;66;03m# Add files and directories\u001b[39;00m\n\u001b[0;32m    775\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m entry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_directoy\u001b[38;5;241m.\u001b[39mvalue:\n",
      "File \u001b[1;32mc:\\Users\\darouich\\OneDrive\\Dokumente\\datamodel_b07_tc\\datamodel_b07_tc\\FAIRFlowChemistry\\tools\\data_processing_widgets.py:654\u001b[0m, in \u001b[0;36mDaRUS_upload.fill_citation\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    652\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDaRUS_data\u001b[38;5;241m.\u001b[39mcitation\u001b[38;5;241m.\u001b[39mtopic_classification \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    653\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m classification \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39mgeneral_information\u001b[38;5;241m.\u001b[39mtopic_classification: \n\u001b[1;32m--> 654\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDaRUS_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcitation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_topic_classification\u001b[49m\u001b[43m(\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m!=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mid\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    656\u001b[0m \u001b[38;5;66;03m# Add keywords\u001b[39;00m\n\u001b[0;32m    657\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mDaRUS_data\u001b[38;5;241m.\u001b[39mcitation\u001b[38;5;241m.\u001b[39mkeyword \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[1;32mc:\\Users\\darouich\\miniconda3\\Lib\\site-packages\\forge\\_revision.py:327\u001b[0m, in \u001b[0;36mRevision.__call__.<locals>.inner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(\u001b[38;5;28mcallable\u001b[39m)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[0;32m    325\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minner\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m    326\u001b[0m     \u001b[38;5;66;03m# pylint: disable=E1102, not-callable\u001b[39;00m\n\u001b[1;32m--> 327\u001b[0m     mapped \u001b[38;5;241m=\u001b[39m \u001b[43minner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__mapper__\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    328\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;241m*\u001b[39mmapped\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmapped\u001b[38;5;241m.\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\darouich\\miniconda3\\Lib\\site-packages\\forge\\_revision.py:109\u001b[0m, in \u001b[0;36mMapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    107\u001b[0m     public_ba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpublic_signature\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m--> 109\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m    110\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{callable_name}\u001b[39;00m\u001b[38;5;124m() \u001b[39m\u001b[38;5;132;01m{message}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39m\\\n\u001b[0;32m    111\u001b[0m         \u001b[38;5;28mformat\u001b[39m(\n\u001b[0;32m    112\u001b[0m             callable_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallable\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m,\n\u001b[0;32m    113\u001b[0m             message\u001b[38;5;241m=\u001b[39mexc\u001b[38;5;241m.\u001b[39margs[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    114\u001b[0m         ),\n\u001b[0;32m    115\u001b[0m     )\n\u001b[0;32m    116\u001b[0m public_ba\u001b[38;5;241m.\u001b[39mapply_defaults()\n\u001b[0;32m    118\u001b[0m private_ba \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprivate_signature\u001b[38;5;241m.\u001b[39mbind_partial()\n",
      "\u001b[1;31mTypeError\u001b[0m: add_topic_classification() got an unexpected keyword argument 'term'"
     ]
    }
   ],
   "source": [
    "# Predefined list of all SFB1333 dataverses. If a new dataverse wants to be appended, just add in the list\n",
    "sfb1333_dataverse_list = [ \"sfb1333-\"+group_name for group_name in [\"hansen-gross\", \"grabowski\", \"sarkar\", \"tallarek\", \"peters\", \"schmitz\", \"inf\", \"pluhackova\", \"giesselmann\", \"klemm\", \"schlaich\", \"traa\", \"naumann\", \"lotsch\", \"vanSlageren\", \"holm\", \"fyta\", \"estes\", \"laschat\", \"bruckner\", \"bill\", \"ludwigs\", \"dyballa\", \"ringenberg\", \"kaestner\", \"Buchmeiser\", \"sottmann\"] ]\n",
    "\n",
    "Darus_upload = DaRUS_upload()\n",
    "\n",
    "Darus_upload.DaRUS( dataset = rrdw.dataset, \n",
    "                    dataset_path = rrdw.dataset_dropdown.value,\n",
    "                    dataverse_list = sfb1333_dataverse_list )\n",
    "\n",
    "Darus_upload.api_token_text.value = \"4afecd82-c92d-4935-b786-2225af43531e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "Darus_upload.DaRUS_data.citation.add_topic_classification()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[TopicClassification(id='topicclassification0', term='homogeneous catalysis (LCSH)', vocabulary=None, vocabulary_url='https://id.loc.gov/authorities/subjects/sh2014001146.html')]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Darus_upload.dataset.general_information.topic_classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter: value\n",
      "Default Value: None\n",
      "Parameter: vocabulary\n",
      "Default Value: None\n",
      "Parameter: vocabulary_uri\n",
      "Default Value: None\n"
     ]
    }
   ],
   "source": [
    "import inspect\n",
    "\n",
    "\n",
    "# Get the arguments and keyword arguments of the function\n",
    "\n",
    "signature = inspect.signature(Darus_upload.DaRUS_data.citation.add_keyword)\n",
    "\n",
    "# Access parameters and their default values\n",
    "parameters = signature.parameters\n",
    "for param_name, param in parameters.items():\n",
    "    print(\"Parameter:\", param_name)\n",
    "    print(\"Default Value:\", param.default)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b07",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f62ab2d43dc75e3c3b007469adeb0f7488873df876b9b71dd3b119f0280ba41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
