{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Workflow for on-line GC and HPLC analysis in flow chemistry</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 0: Imports, Paths, and Logging\n",
    "---\n",
    "\n",
    "In this section all the necessary python packages are imported, the path to this notebook and the logger for this notebook is set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate autoreload to keep on track with changing modules #\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import standard libraries #\n",
    "import numpy as np\n",
    "import logging\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "# Import tools for data processing and analysis #\n",
    "from datamodel.tools import initialize_dataset\n",
    "from datamodel.tools import reading_raw_data_widget\n",
    "from datamodel.tools import analyzing_raw_data_widget\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths for loggin output #\n",
    "root                = Path.cwd()\n",
    "logging_config_path = root / \"datamodel/tools/logger_config.json\"\n",
    "\n",
    "# Read in logger specs and configurate logger (set name to current notebook) #\n",
    "with open(logging_config_path) as logging_config_json: logging.config.dictConfig( json.load( logging_config_json ) )\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the level of thid-party logger to avoid dumping too much information #\n",
    "for logger_ in ['markdown_it', 'h5py', 'numexpr', 'git']: logging.getLogger(logger_).setLevel('WARNING')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Dataset and raw data\n",
    "---\n",
    "In this section the dataset as well as the to analyze raw data is choosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da6c14d105e14f528a8bf95eef8b4f1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Choose datamodel', layout=Layout(width='auto'), options=((…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "git_path = 'https://github.com/FAIRChemistry/datamodel_b07_tc.git'\n",
    "branch   = 'samir_develop'\n",
    "\n",
    "id = initialize_dataset()\n",
    "id.write_dataset(root, git_path, branch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Definition of basic meta data of the project ##\n",
    "\n",
    "id.title.value        = 'Electrocatalytic CO2-reduction on carbon'\n",
    "id.description.value  = 'The aim of this project is to blablabla'\n",
    "id.project.value      = 'Project B07'\n",
    "\n",
    "# List with authors and their affiliation #\n",
    "id.authors.value      = 'Richard Schömig, Maximilian Schmidt' \n",
    "id.affiliations.value = 'University of Stuttgart, University of Stuttgart'\n",
    "id.identifier.value   = 'xxx-xxx-xxx-xxx, xxx-xxx-xxx-xxx'\n",
    "id.contact_text.value = 'Richard Schömig, richard@web.de'\n",
    "\n",
    "id.related_publication.value = \"test, https\"\n",
    "\n",
    "id.topic_classification.value = \"homogeneous catalysis (LCSH), https://id.loc.gov/authorities/subjects/sh2014001146.html\"\n",
    "id.keywords.value             = \"polymer chemistry (Loterre Chemistry Vocabulary), https://skosmos.loterre.fr/ERC/en/page/?uri=http%3A%2F%2Fdata.loterre.fr%2Fark%3A%2F67375%2FERC-KCSKD4X9-P\"\n",
    "\n",
    "id.dataset_text.value = \"test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0623f697282d45b9b2f385eb3589f426",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Choose dataset', layout=Layout(width='auto'), options=(('b…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Search for dataset and raw data ##\n",
    "\n",
    "rrdw = reading_raw_data_widget()\n",
    "rrdw.choose_data(root)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#str(root) = \"c:/Users/darouich/OneDrive/Dokumente/\"\n",
    "\n",
    "e_chem = str(root)+'/data/Rohdaten/01_EChem/CAD14-Cu@AB/GSTATIC.DTA'\n",
    "mfm    = str(root)+'/data/Rohdaten/03_MFM/CAD14-Cu@AB/Bench-2h-GSS_CAD14-Cu@AB_200_50c_24h_truncated.csv'\n",
    "gc     = [str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0102.D/report00.CSV',\n",
    "        str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0102.D/REPORT01.CSV',\n",
    "        str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0103.D/report00.CSV',\n",
    "        str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0103.D/REPORT01.CSV',\n",
    "        str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0104.D/report00.CSV',\n",
    "        str(root)+'/data/Rohdaten/02_GC/CAD14-Cu@AB/JH-1H 2023-02-06 10-00-18/NV-F0104.D/REPORT01.CSV']\n",
    "calib  = str(root)+'/data/calibration/calibration.json'\n",
    "correc = str(root)+'/data/correction_factors/correction_factors.json'\n",
    "farada = str(root)+'/data/faraday_coefficients/faraday_coefficients.json'\n",
    "\n",
    "rrdw.Echem_files.value = [e_chem]\n",
    "rrdw.MFM_files.value   = [mfm]\n",
    "rrdw.GC_files.value    = gc\n",
    "rrdw.calib_files.value = [calib]\n",
    "rrdw.correction_files.value = [correc]\n",
    "rrdw.faraday_files.value    = [farada]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Analysis of data\n",
    "---\n",
    "In this section the raw data of the above choosen dataset is analyzed (if you change the dataset above, then reexecute this cell)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25fd65e4b69b46349c7f0bd7449c6cc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Choose experiment:', layout=Layout(width='auto'), options=…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da3a0bd8b7e34ea1b6d6cef38897a5ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(Label(value='Measurement number 0', layout=Layout(height='30px', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71081c5ad3c341c09c1f919960f126b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(VBox(children=(VBox(children=(HTML(value='The mass flow at the time of the GC measurement is de…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Provide a typical retention time dictionary to pre assign retention times \n",
    "\n",
    "typical_retention_time = {\"Hydrogen\": 1.7, \"Carbon dioxide\": 3.0, \"Carbon monoxide\": 13.6, \n",
    "                          \"Methane\": 3.6, \"Ethene\": 6.0, \"Ethane\": 7.1}\n",
    "\n",
    "ardw = analyzing_raw_data_widget()\n",
    "ardw.choose_experiment( datamodel = rrdw.datamodel, \n",
    "                        dataset_path = rrdw.dataset_dropdown.value, \n",
    "                        typical_retention_time = typical_retention_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Upload of data to DaRUS\n",
    "---\n",
    "In this section the dataset containing the processed as well as the raw data, is uploaded to DaRUS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, clear_output\n",
    "from pyDaRUS import Citation\n",
    "from pyDaRUS import Dataset as DaRUS_dataset\n",
    "from pyDaRUS.metadatablocks.citation import SubjectEnum, IdentifierScheme, RelatedPublication, TopicClassification, Keyword\n",
    "from datetime import datetime\n",
    "\n",
    "import os\n",
    "import ipywidgets as widgets\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from IPython.display import display, clear_output\n",
    "\n",
    "# Import modified sdRDM objects #\n",
    "from sdRDM import DataModel\n",
    "\n",
    "# Import general tools and objects of this datamodel #\n",
    "\n",
    "# Objects #\n",
    "from datamodel.core import Experiment\n",
    "from datamodel.core import MeasurementType\n",
    "from datamodel.core import Quantity\n",
    "\n",
    "# Tools #\n",
    "from datamodel.tools.auxiliary import Librarian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DaRUS_upload:\n",
    "\n",
    "    def upload_to_DaRUS(self,_):\n",
    "\n",
    "        #### Initialize and write DaRUS dataset ####\n",
    "\n",
    "        DaRUS_dataset = DaRUS_dataset()\n",
    "\n",
    "        ## Get citation metadata from the general information object of the provided dataset ##\n",
    "\n",
    "        citation      = Citation()\n",
    "        \n",
    "        ## **{k:author.__dict__[k] for k in author.__dict__.keys() if k!=\"id\"}\n",
    "\n",
    "        # Extract general information from the provided dataset\n",
    "        citation.add_project( name = self.dataset.general_information.project, level=1 )\n",
    "        \n",
    "        citation.title = self.dataset.general_information.title\n",
    "        \n",
    "        for author in self.dataset.general_information.authors: \n",
    "            citation.add_author( **{k:author.__dict__[k] for k in author.__dict__.keys() if k!=\"id\"} ) \n",
    "\n",
    "        citation.add_contact( **{k:self.dataset.general_information.contact.__dict__[k] for k in self.dataset.general_information.contact.__dict__.keys() if k!=\"id\"} ) \n",
    "\n",
    "        citation.subject      = self.dataset.general_information.subject\n",
    "\n",
    "        citation.depositor    = self.depositor_text.value.strip()\n",
    "        citation.deposit_date = datetime.now().date().strftime(\"%Y-%m-%d\")\n",
    "        \n",
    "        citation.add_grant_information( grant_agency=\"DFG\", grant_number=\"358283783 - SFB 1333\")\n",
    "\n",
    "        citation.language     = \"English\"\n",
    "\n",
    "        citation.add_related_publication( **{k:self.dataset.general_information.related_publication.__dict__[k] for k in self.dataset.general_information.related_publication.__dict__.keys() if k!=\"id\"})\n",
    "        \n",
    "        for classification in self.dataset.general_information.topic_classifications: \n",
    "            citation.add_topic_classification( **{k:classification.__dict__[k] for k in classification.__dict__.keys() if k!=\"id\"} )\n",
    "\n",
    "        for keyword in self.dataset.general_information.keywords:\n",
    "            citation.add_keyword( **{k:keyword.__dict__[k] for k in keyword.__dict__.keys() if k!=\"id\"} ) \n",
    "\n",
    "        DaRUS_dataset.add_metadatablock(citation)\n",
    "\n",
    "\n",
    "        ## Add files and directories ##\n",
    "\n",
    "        #DaRUS_dataset.add_directory(\"Examples/dataset_upload/\")\n",
    "        #DaRUS_dataset.add_file(dv_path=\"my.file\", local_path=\"my.file\")\n",
    "\n",
    "        ## Upload ##\n",
    "\n",
    "        DaRUS_dataset.upload(dataverse_name = self.dataverse_dropdown.value,\n",
    "                             DATAVERSE_URL  = \"https://darus.uni-stuttgart.de\",\n",
    "                             API_TOKEN      = self.api_token_text.value)\n",
    "\n",
    "    def upload(self,datamodel,dataset_path,dataverse_list):\n",
    "        \n",
    "        # Common variables\n",
    "\n",
    "        self.dataset_path           = dataset_path\n",
    "        self.dataset, self.lib      = datamodel\n",
    "        \n",
    "        self.dataverse_dropdown     = widgets.Dropdown(options= dataverse_list,\n",
    "                                                    description=\"Choose dataverse:\",\n",
    "                                                    layout=widgets.Layout(width='auto'),\n",
    "                                                    style={'description_width': 'auto'})\n",
    "        \n",
    "        self.depositor_text         = widgets.Text (description=\"Depositor:\",\n",
    "                                                    placeholder=\"Name of the person uploading this dataset (e.g.: Max Mustermann)\",\n",
    "                                                    layout=widgets.Layout(width='auto'),\n",
    "                                                    style={'description_width': 'auto'})\n",
    "        \n",
    "        self.api_token_text         = widgets.Text (description=\"API token:\",\n",
    "                                                    placeholder=\"Provide personal API token from DaRUS (e.g.: xxx-xxx-xxx-xxx-xxx)\",\n",
    "                                                    layout=widgets.Layout(width='auto'),\n",
    "                                                    style={'description_width': 'auto'})\n",
    "\n",
    "        \n",
    "        \n",
    "        self.button_upload          = widgets.Button(description='Upload dataset to DaRUS',\n",
    "                                                     layout=widgets.Layout(width=\"30%\"),\n",
    "                                                     style={\"button_color\": 'lightblue'})\n",
    "        \n",
    "        # Handle button\n",
    "        self.button_upload.on_click(self.upload_to_DaRUS)\n",
    "\n",
    "        # Widgets\n",
    "        v_space   = widgets.VBox([widgets.Label(value='')], layout=widgets.Layout(height='30px'))\n",
    "        h_space   = widgets.HBox([widgets.Label(value='')], layout=widgets.Layout(width='30px'))\n",
    "\n",
    "        widgets0  = widgets.HBox([self.dataverse_dropdown, v_space])\n",
    "        widgets1  = widgets.VBox([self.depositor_text, self.api_token_text,v_space])\n",
    "        widgets2  = widgets.VBox([self.button_upload],layout=widgets.Layout(align_items = 'center'))\n",
    "\n",
    "        # Combine the layout\n",
    "        full_layout = widgets.VBox([widgets0, widgets1, widgets2])\n",
    "\n",
    "        # Display the layout\n",
    "        display(full_layout)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To do: add file and directory selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0d4c09c467b447fbd8ae26cd8850d1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Dropdown(description='Choose dataverse:', layout=Layout(width='auto'), options=(…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sfb1333_dataverse_list = [ \"sfb1333-hansen-gross\" ]\n",
    "\n",
    "api_token = \"4afecd82-c92d-4935-b786-2225af43531e\"\n",
    "\n",
    "test = DaRUS_upload()\n",
    "\n",
    "test.upload( datamodel = rrdw.datamodel, \n",
    "             dataset_path = rrdw.dataset_dropdown.value,\n",
    "             dataverse_list = sfb1333_dataverse_list )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b07",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f62ab2d43dc75e3c3b007469adeb0f7488873df876b9b71dd3b119f0280ba41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
