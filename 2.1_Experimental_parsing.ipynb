{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Workflow for on-line GC and HPLC analysis in flow chemistry</center>\n",
    "# <center>2.1 Experimental notebook - Parsing</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "This is the ``Experimental`` ``notebook`` ``2.1 \"Parsing\"``, where all the relevent data of the experiments are read in from different ressources. For each individual experiment this workflow is to be executed once, and the data can be appended to the project's dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 0: Imports, Paths, and Logging\n",
    "---\n",
    "\n",
    "In this section all the necessary python packages are imported, the path to this notebook and the logger for this notebook is set up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Activate autoreload to keep on track with changing modules #\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "# Import standard libraries #\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "\n",
    "# Import librarian module for file directory handling #\n",
    "from datamodel_b07_tc.tools import Librarian\n",
    "\n",
    "# Import modified sdRDM objects #\n",
    "from datamodel_b07_tc.modified.experiment import Experiment\n",
    "from datamodel_b07_tc.modified.measurement import Measurement\n",
    "from datamodel_b07_tc.modified.plantsetup import PlantSetup\n",
    "\n",
    "# Import datamodel from sdRDM #\n",
    "from sdRDM import DataModel\n",
    "\n",
    "# Import tools for parsing and calibration of the raw data #\n",
    "from datamodel_b07_tc.tools import Calibrator\n",
    "from datamodel_b07_tc.tools import gc_parser\n",
    "from datamodel_b07_tc.tools import gstatic_parser\n",
    "from datamodel_b07_tc.tools import mfm_parser\n",
    "# from datamodel_b07_tc.tools import DEXPI2sdRDM\n",
    "\n",
    "# from sdRDM.generator import generate_python_api\n",
    "# generate_python_api('specifications/datamodel_b07_tc.md', '', 'datamodel_b07_tc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define paths for loggin output #\n",
    "root                = Path.cwd()\n",
    "logging_config_path = root / \"datamodel_b07_tc/tools/logging/config_exp_2_1.json\"\n",
    "\n",
    "# Read in logger specs and configurate logger (set name to current notebook) #\n",
    "with open(logging_config_path) as logging_config_json: logging.config.dictConfig( json.load( logging_config_json ) )\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the level of thid-party logger to avoid dumping too much information #\n",
    "third_party_module_loggers = ['markdown_it', 'h5py', 'numexpr', 'git']\n",
    "for logger_ in third_party_module_loggers: logging.getLogger(logger_).setLevel('WARNING')\n",
    "\n",
    "# Initialize the librarian with root directory of this notebook #\n",
    "librarian = Librarian(root_directory=root)\n",
    "\n",
    "# Info for loggers #\n",
    "# Some third party modules use the same logging module and structure as this notebook, which is unproblematic, \n",
    "# unless the level of their corresponding logging handlers is too low. In these cases the logging messages of \n",
    "# lower levels, such as 'DEBUG' and 'INFO' are propagated to the parent logger of this notebook.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 1: Dataset and data model parsing\n",
    "---\n",
    "In this section the data model and the dataset as well as all the output files necessary for the analysis notenook are parsed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent directory: \n",
      " /Users/samir/Documents/PhD/SFB1333/datamodel_b07_tc \n",
      "Available subdirectories:\n",
      "0: .../specifications\n",
      "1: .../datasets\n",
      "2: .../datamodel_b07_tc\n",
      "3: .../.github\n",
      "4: .../.git\n",
      "5: .../data\n",
      "\n",
      "\n",
      "Directory: \n",
      " /Users/samir/Documents/PhD/SFB1333/datamodel_b07_tc/datasets \n",
      "Available files:\n",
      "0: b07.json\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Check for all available subdirectories #\n",
    "root_subdirectories = librarian.enumerate_subdirectories(directory=root)\n",
    "print(\"\\n\")\n",
    "\n",
    "# Search for subdirectory \"datasets\" and in it for all dataset json files #\n",
    "idx_dataset        = [i for i in range(len(root_subdirectories)) if str(root_subdirectories[i]).split(\"/\")[-1] == \"datasets\" ][0]\n",
    "json_dataset_files = librarian.enumerate_files(directory=root_subdirectories[idx_dataset], filter='json')\n",
    "print(\"\\n\")\n",
    "\n",
    "# Choose dataset: use the index given. e.g.: 0, 1, .. #\n",
    "json_dataset = json_dataset_files[0]\n",
    "dataset, lib = DataModel.parse(json_dataset)\n",
    "\n",
    "# If wanted visualize the datamodel as tree (if not then commen this line) #\n",
    "#lib.Dataset.meta_tree()\n",
    "\n",
    "# Find the data folder #\n",
    "idx_datafolder          = [i for i in range(len(root_subdirectories)) if str(root_subdirectories[i]).split(\"/\")[-1] == \"data\" ]\n",
    "data_subdirectories     = librarian.enumerate_subdirectories(directory=root_subdirectories[idx_datafolder])\n",
    "\n",
    "# Find the raw data folders #\n",
    "idx_rawdatafolder       = [i for i in range(len(data_subdirectories)) if str(data_subdirectories[i]).split(\"/\")[-1] == \"Rohdaten\" ]\n",
    "raw_data_subdirectories = librarian.enumerate_subdirectories(directory=data_subdirectories[idx_rawdatafolder])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 2: Plant setup parsing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate 'experiment' object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment()\n",
    "\n",
    "## Get plan setup given as in dexpi format ##\n",
    "\n",
    "#idx_rawdatafolder       = [i for i in range(len(data_subdirectories)) if str(data_subdirectories[i]).split(\"/\")[-1] == \"plant_setup\" ]\n",
    "#plant_setup_files = librarian.enumerate_files(dirctory=data_subdirectories[idx_rawdatafolder], filter='xml')\n",
    "#plant_setup = PlantSetup.from_parser(parser=DEXPI2sdRDM, path=plant_setup_files[0])\n",
    "#experiment.plant_setup = plant_setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 3: Potenstiostatic data parsing\n",
    "---\n",
    "Select path to the potentiostatic data and print available subdirectories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search for the electrochemical data folder #\n",
    "idx_echem_direct  = [i for i in range(len(raw_data_subdirectories)) if str(raw_data_subdirectories[i]).split(\"/\")[-1] == \"01_EChem\" ]\n",
    "echem_directories = librarian.enumerate_subdirectories(directory=raw_data_subdirectories[idx_echem_direct])\n",
    "\n",
    "# Serach the potentiostatic files #\n",
    "idx_potentiostatic_files      = [i for i in range(len(echem_directories)) if str(echem_directories[i]).split(\"/\")[-1] == \"CAD14-Cu@AB\" ]\n",
    "potentiostatic_raw_data_files = librarian.enumerate_files(directory=echem_directories[idx_potentiostatic_files], filter='DTA')\n",
    "\n",
    "# Read in the gstatic data #\n",
    "idx_gstatic_dat   = [i for i in range(len(potentiostatic_raw_data_files)) if str(potentiostatic_raw_data_files[i]).split(\"/\")[-1] == \"GSTATIC.DTA\" ]\n",
    "potentiostatic_metadata_df, potentiostatic_measurement = Measurement.from_parser(parser=gstatic_parser, metadata_path=potentiostatic_raw_data_files[idx_gstatic_dat])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 4: MFM data parsing\n",
    "---\n",
    "Provide name of the subdirectory containing the mass flow meter measurement data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent directory: \n",
      " /mnt/c/Users/rscho/Documents/GitHub/datamodel_b07_tc/data/Rohdaten/03_MFM \n",
      "Available subdirectories:\n",
      "0: .../CAD14-Cu@AB\n"
     ]
    }
   ],
   "source": [
    "# Search for mass flow meter data folder #\n",
    "idx_mfm_direct  = [i for i in range(len(raw_data_subdirectories)) if str(raw_data_subdirectories[i]).split(\"/\")[-1] == \"03_MFM\" ]\n",
    "mfm_directories = librarian.enumerate_subdirectories(directory=raw_data_subdirectories[idx_mfm_direct])\n",
    "\n",
    "# Serach for the csv output files #\n",
    "idx_mfm_files      = [i for i in range(len(mfm_directories)) if str(mfm_directories[i]).split(\"/\")[-1] == \"CAD14-Cu@AB\" ]\n",
    "mfm_raw_data_files = librarian.enumerate_files(directory=mfm_directories[idx_mfm_files], filter='csv')\n",
    "\n",
    "# Manually select the wanted csv file and read it in #\n",
    "idx_mfm_file       = 0\n",
    "mfm_experimental_data_df, mfm_measurement = Measurement.from_parser(parser=mfm_parser, experimental_data_path=mfm_raw_data_files[idx_mfm_file])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 5: GC data parsing\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parent directory: \n",
      " /mnt/c/Users/rscho/Documents/GitHub/datamodel_b07_tc/data/Rohdaten/02_GC \n",
      "Available subdirectories:\n",
      "0: .../CAD14-Cu@AB\n"
     ]
    }
   ],
   "source": [
    "# Search for mass flow meter data folder #\n",
    "idx_gc_direct  = [i for i in range(len(raw_data_subdirectories)) if str(raw_data_subdirectories[i]).split(\"/\")[-1] == \"02_GC\" ]\n",
    "gc_directories = librarian.enumerate_subdirectories(directory=raw_data_subdirectories[idx_gc_direct])\n",
    "\n",
    "# Serach for gc subdirectories #\n",
    "idx_gc_sub_dir    = [i for i in range(len(gc_directories)) if str(gc_directories[i]).split(\"/\")[-1] == \"CAD14-Cu@AB\" ]\n",
    "gc_subdirectories = librarian.enumerate_subdirectories(directory=gc_directories[idx_gc_sub_dir])\n",
    "\n",
    "# Select subdirectory of wanted experiment from given directories #\n",
    "idx_gc_sub_sub_dir   = 0\n",
    "gc_subsubdirectories = librarian.enumerate_subdirectories(directory=gc_subdirectories[idx_gc_sub_sub_dir])\n",
    "\n",
    "# Gather all the gc raw data files #\n",
    "gc_raw_data_files_list = []\n",
    "\n",
    "# Select the indices of the subdirectories that should be read in\n",
    "gc_raw_data_subdir_idx = [ 3, 4, 5 ] \n",
    "\n",
    "gc_raw_data_files_list = [librarian.enumerate_files(directory=gc_subsubdirectories[i], filter='CSV') for i in gc_raw_data_subdir_idx]\n",
    "\n",
    "# Read out all the data from the provided gc files #\n",
    "gc_experimental_data_df_list = []\n",
    "gc_metadata_df_list = []\n",
    "gc_measurements_list = []\n",
    "\n",
    "for data_file in gc_raw_data_files_list:\n",
    "    gc_metadata_df, gc_experimental_data_df, gc_measurement = Measurement.from_parser(\n",
    "        parser=gc_parser,\n",
    "        metadata_path=data_file[0],\n",
    "        experimental_data_path=data_file[1]\n",
    "    )\n",
    "    gc_experimental_data_df_list.append(gc_experimental_data_df)\n",
    "    gc_metadata_df_list.append(gc_metadata_df)\n",
    "    gc_measurements_list.append(gc_measurement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Combine all gathered data in the experiments object ##\n",
    "\n",
    "experiment.measurements = [potentiostatic_measurement, mfm_measurement, *gc_measurements_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 6: Calibration data parsing\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for calibation files in the 'calibration' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: \n",
      " /mnt/c/Users/rscho/Documents/GitHub/datamodel_b07_tc/data/calibration \n",
      "Available files:\n",
      "0: calibration.json\n"
     ]
    }
   ],
   "source": [
    "calibration_files = librarian.enumerate_files(directory=data_subdirectories[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize calibrator with an available calibration file selected by its index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "calibrator = Calibrator.from_json_file(path_to_json_file=calibration_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibrate and return analysis object with calibration parameters just computed. <br> Append the resulting SpeciesData objects to the experiment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "species_data_list = calibrator.calibrate()\n",
    "experiment.species_data = species_data_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 7: Parsing auxiliary data\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correction factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for correction factors files in the 'correction factors' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: \n",
      " /mnt/c/Users/rscho/Documents/GitHub/datamodel_b07_tc/data/correction_factors \n",
      "Available files:\n",
      "0: correction_factors.json\n"
     ]
    }
   ],
   "source": [
    "correction_factors_files = librarian.enumerate_files(directory=data_subdirectories[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load correction factors into the experiment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.read_correction_factors(correction_factors_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Farady coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for faraday coefficients files in the 'correction factors' directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: \n",
      " /mnt/c/Users/rscho/Documents/GitHub/datamodel_b07_tc/data/faraday_coefficients \n",
      "Available files:\n",
      "0: faraday_coefficients.json\n"
     ]
    }
   ],
   "source": [
    "faraday_coefficients_files = librarian.enumerate_files(directory=data_subdirectories[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load faraday coefficients into the experiment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment.read_faraday_coefficients(faraday_coefficients_files[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Electrode surface area"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set value for the surface area of the electrode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "electrode_surface_area = 1.0 # cm^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Section 8: Appending parsed data to dataset\n",
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print current state of experiment object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(experiment.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Append experiment object to the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.experiments.append(experiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace 'old' dataset by its extended version containing all the parsef data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(json_dataset, \"w\") as f:\n",
    "    f.write(dataset.json())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b07",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f62ab2d43dc75e3c3b007469adeb0f7488873df876b9b71dd3b119f0280ba41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
