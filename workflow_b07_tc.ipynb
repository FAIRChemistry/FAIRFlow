{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow for the CRC1333 project B07 - Technical Chemistry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import necessary packages.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "from datetime import datetime\n",
    "from sdRDM import DataModel\n",
    "from modules import GCParser\n",
    "from modules import GstaticParser\n",
    "from modules import MFMParser\n",
    "from modules import Calculator\n",
    "from pathlib import Path\n",
    "# from DEXPI2sdRDM import DEXPI2sdRDM"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the data model and the correct path to the working directory."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load data model from markdown file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DataModel.from_markdown('specifications/datamodel_b07_tc.md')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = DataModel.from_git(url='https://github.com/FAIRChemistry/datamodel_b07_tc.git')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set path to current working directory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dataset = Path.cwd()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Initialize Dataset of the project.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b07 = model.Dataset()\n",
    "b07.__dict__"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Store general information about the project like the title of the project, the authors and a project description into the data model.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_inf = model.GeneralInformation()\n",
    "title = 'Electrocatalytic CO2-reduction on carbon'\n",
    "gen_inf.title = title\n",
    "description = 'The aim of this project is to blablabla'\n",
    "gen_inf.description = description\n",
    "author_1 = model.Author(name= 'Richard Sch√∂mig', affiliation = 'University of Stuttgart')\n",
    "author_2 = model.Author(name= 'Maximilian Schmidt', affiliation = 'University of Stuttgart')\n",
    "gen_inf.authors = [author_1, author_2]\n",
    "b07.general_information= gen_inf\n",
    "# b07.general_information = gen_inf\n",
    "# gen_inf.add_to_authors(name='test')\n",
    "# gen_inf.add_to_authors(name='test')\n",
    "print(b07.__dict__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculation=model.Calculation(calibrations= list(cali_dict.values()))\n",
    "# experiment_1=model.Experiment(calculations=calculation)\n",
    "# b07=model.Dataset(experiments=[experiment_1])\n",
    "# # b07.add_experiment_to_experiments(experiment_1)\n",
    "# b07.general_information=general_information\n",
    "# b07.__dict__\n",
    "# # b07"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Instantiate an experiment objects which holds all the information about one single experiment.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = model.Experiment()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load metadata into the datamodel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load P&ID file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = \"column\"\n",
    "# path = \"./f'{filename}'\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load DEXPI conform P&ID file into the data model using the ``DEXPI2sdRDM`` module.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEXPI2sdRDM(\n",
    "# )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an instance of the ``GstaticParser`` to parse Gamry output files and show available files in the selected directory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gstaticparser = GstaticParser(path_to_dataset / 'data')\n",
    "dict_of_gstatic_files = gstaticparser.enumerate_available_files()\n",
    "for index, gstatic_file in dict_of_gstatic_files.items():\n",
    "    print(f\"{index}: {gstatic_file}\")\n",
    "# available_files = gstaticparser.available_files\n",
    "# print(available_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# measurements = model.Measurement()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chose specific file and extract the metadata from it using the ``GstaticParser``.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gstatic_file = dict_of_gstatic_files[0]\n",
    "gstatic_meta_df, gstatic_meta = gstaticparser.extract_metadata(gstatic_file)\n",
    "# ExPot = model.PotentiostaticMeasurement()\n",
    "# experiment.add_to_measurements(gstatic_meta)\n",
    "experiment.measurements = [gstatic_meta]\n",
    "# gstatic_meta_df\n",
    "# experiment.__dict__\n",
    "# b07.add_to_experiments(experiment)\n",
    "b07.experiments=[experiment]\n",
    "print(b07.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get initial current in mA and initial time in s.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_IINIT = '{measurements {metadata (abbreviation: IINIT) {parameter}}}'\n",
    "I_init= float(b07.query(query_IINIT)['measurements'][0]['metadata'][0]['parameter'])\n",
    "\n",
    "query_TINIT = '{measurements {metadata (abbreviation: TINIT) {parameter}}}'\n",
    "T_init = float(b07.query(query_TINIT)['measurements'][0]['metadata'][0]['parameter'])\n",
    "\n",
    "I_init, T_init"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an instance of the ``MFMParser`` to parse MFM output files and show available files in the selected directory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfmparser = MFMParser(path_to_dataset / 'data')\n",
    "dict_of_mfm_files = mfmparser.enumerate_available_files()\n",
    "for index, mfmfile in dict_of_mfm_files.items():\n",
    "    print(f\"{index}: {mfmfile}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chose specific file and extract the metadata from it using the ``MFMParser``.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfm_file = dict_of_mfm_files[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.enums.Unit.MILLILITERPERSECOND.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mfm_exp_data_df, mfm_exp_data = mfmparser.extract_exp_data(mfm_file)\n",
    "# mfm_exp_data_df\n",
    "# mfm_exp_data_df['datetime']#.dt.to_pydatetime()\n",
    "# pd.to_datetime(mfm_exp_data_df['datetime'])#.tolist()\n",
    "# mfm_exp_data_df.dropna().to_csv('mfm_exp_data_df.csv')\n",
    "# list_of_types = mfmparser.extract_exp_data(mfm_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timestamp_object = mfm_exp_data_df.at[100000,'datetime'].to_pydatetime()\n",
    "timestamp_object\n",
    "# datetime.fromtimestamp(timestamp_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcparser = GCParser(path_to_dataset / 'data')\n",
    "dict_of_gcmd_files = gcparser.enumerate_available_files()\n",
    "for index, gcmd_file in dict_of_gcmd_files.items():\n",
    "    print(f\"{index}: {gcmd_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcmd_file = dict_of_gcmd_files[0]\n",
    "# print(gcmdparser._available_files[gcm]\n",
    "# )\n",
    "metadata, metadata_df = gcparser.extract_metadata(gcmd_file)\n",
    "metadata_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_date = metadata_df.at[9, 'column_2']\n",
    "inj_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inj_date_datetime = datetime.strptime(inj_date, '%d-%b-%y, %H:%M:%S')\n",
    "inj_date_datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_flow = []\n",
    "m = 10\n",
    "for i, time in enumerate(mfm_exp_data_df['datetime']):\n",
    "    if time.to_pydatetime() == inj_date_datetime:\n",
    "        for j in range(i-m,i+m+1):\n",
    "            vol_flow.append(mfm_exp_data_df.at[j,'flow'])\n",
    "vol_flow_mean = sum(vol_flow) / (m*2+1)\n",
    "vol_flow_mean"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Create an instance of the ``GCEDParser`` to parse GC experimental data output files and show available files in the selected directory.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcedparser = GCEDParser(path_to_dataset / 'data')\n",
    "dict_of_gced_files = gcedparser.enumerate_available_files()\n",
    "for index, gced_file in dict_of_gced_files.items():\n",
    "    print(f\"{index}: {gced_file}\")\n",
    "# available_files = parser.available_files\n",
    "# print(available_files)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Chose specific file and extract the metadata from it using the ``GCParser``.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcedfile = dict_of_gced_files[1]\n",
    "exp_df = gcedparser.extract_exp_data(gced_file)\n",
    "exp_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Assign peak areas to species.** \\\n",
    "The peak areas recorded by the GC have to be matched with the correct species. The individial ``Area`` is selected by its corresponding ``Peak_Number``. It is possible that the same species is accountable for multiple peaks, i.d. multiple peaks are assigned to the same species.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assign_peak_dict={\n",
    "    'CO2': [2],\n",
    "    'CO': [6],\n",
    "    'H2': [1],\n",
    "    'CH4': [3],\n",
    "    'C2H4': [5],\n",
    "    # 'C2H6': [4],\n",
    "}\n",
    "peak_area_dict = {}\n",
    "for key, value in assign_peak_dict.items():\n",
    "    peak_area_dict[key]=exp_df.query('Peak_Number==@value')['Area'].sum()\n",
    "peak_area_dict"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Set calibration input values and import into the data model.** \\\n",
    "To determine the concentrations of the individual species, a calibration has to be performed in advance to match the individual values for ``Area`` with their corresponding concentrations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_input_dict={\n",
    "    'CO2': [[0,38653],[0,50]],\n",
    "    'CO':[[797,1328,7223],[0.5,1,5]],\n",
    "    'H2':[[71,153,330], [5,10,20]],\n",
    "    'CH4':[[5727,11991], [5,10]],\n",
    "    'C2H4':[[1122,4864,7297], [0.5,2,3]],\n",
    "    'C2H6':[[0,12168], [0,5]],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_dict={}\n",
    "for key, value in cali_input_dict.items():\n",
    "    cali_dict[key]=model.Calibration(\n",
    "        peak_area=[\n",
    "            model.Data(\n",
    "                values=value[0],\n",
    "                # unit=model.\n",
    "                unit=model.enums.Unit.VOLFRACTION\n",
    "            )\n",
    "        ],\n",
    "        concentration=[\n",
    "            model.Data(  \n",
    "                values=value[1],\n",
    "                unit=model.enums.Unit.VOLFRACTION\n",
    "            )\n",
    "        ]    \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b07.general_information.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.Datamodel.visualize_tree("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.Dataset.visualize_tree()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instantiate the ``Calculator`` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculator=Calculator(path_to_dataset=path_to_dataset)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calibrate using the ``calibrate`` method of the ``Calculator`` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cali_result_df=calculator.calibrate(calibration_input_dict=cali_input_dict)\n",
    "cali_result_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate volume fractions using the ``calculate_volume_fractions`` method of the ``Calculator`` module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_frac_df = calculator.calculate_volume_fractions(peak_area_dict=peak_area_dict, calibration_result_df=cali_result_df)\n",
    "vol_frac_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculate the conversion factors of the individual species using the ``calculate_conversion_factors`` method of the ``Calculator`` module and the correction factors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_corr_dict= {\n",
    "    'H2':1.01,\n",
    "    'CO':0.74,\n",
    "    'CO2':1.00,\n",
    "    'CH4':0.76,\n",
    "    # 'C2H4':,\n",
    "    # 'C2H6':,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_frac_df.loc['H2'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_conv = calculator.calculate_conversion_factor(volume_fractions=vol_frac_df, correction_factors=f_corr_dict)\n",
    "f_conv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol_flow_r_df = calculator.calculate_vol_flow_r(conversion_factor = f_conv, volumetric_flow_measured = mfm_exp_data_df )\n",
    "vol_flow_r_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DirectedGraph:\n",
    "    \n",
    "#     def __init__(self, name, connections):\n",
    "#         self.name = name\n",
    "#         self.connections = connections\n",
    "#         self.connec_tuple = []\n",
    "#         self.make_connectivity()\n",
    "\n",
    "        \n",
    "#     def make_connectivity(self):\n",
    "#         if len(self.connections) == 0: \n",
    "#             return([])\n",
    "#         for connection in self.connections:\n",
    "#             self.connec_tuple.append((self.name, connection))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mod_1 = DirectedGraph(input0, [tubing0])\n",
    "# mod_2 = DirectedGraph(input1, [tubing1])\n",
    "# mod_3 = DirectedGraph(tubing0, [valve0])\n",
    "# mod_4 = DirectedGraph(tubing1, [valve0])\n",
    "# mod_5 = DirectedGraph(valve0, [tubing2])\n",
    "# mod_6 = DirectedGraph(fc, [tubing2])\n",
    "# mod_7 = DirectedGraph(tubing2, [valve1])\n",
    "# mod_8 = DirectedGraph(valve1, [tubing4])\n",
    "# mod_9 = DirectedGraph(tubing4, [valve2])\n",
    "# mod_10 = DirectedGraph(valve2, [tubing5])\n",
    "# mod_11 = DirectedGraph(tubing5, [gc])\n",
    "# mod_12 = DirectedGraph(tubing5, [fr])\n",
    "\n",
    "# modules = [mod_1, mod_2, mod_3, mod_4, mod_5, mod_6, mod_7, mod_8, mod_9, mod_10, mod_11, mod_12]\n",
    "# module_names = [flow_mod.name for flow_mod in modules]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# area = exp_df['Area']\n",
    "# peak_area_dict = {\n",
    "#     'co2': area.iloc[[1]].sum(),\n",
    "#     'co': area.iloc[[5,6]].sum(),\n",
    "#     'h2': area.iloc[[0]].sum(),\n",
    "#     'ch4': area.iloc[[2,3]].sum(),\n",
    "#     'c2h4': area.iloc[[4]].sum(),\n",
    "#     # 'c2h6': area.iloc[[0,1]].sum()\n",
    "# }\n",
    "# peak_area_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flowG = nx.DiGraph()\n",
    "# flowG.add_nodes_from(module_names)\n",
    "# for module in modules:\n",
    "#     flowG.add_edges_from(module.connec_tuple)\n",
    "# my_pos = nx.spring_layout(flowG, seed = 5) # this fixes the style of the graph, if it's ugly change the seed\n",
    "# nx.draw(flowG, pos = my_pos, with_labels=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "b07",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9f62ab2d43dc75e3c3b007469adeb0f7488873df876b9b71dd3b119f0280ba41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
